{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **DIABETES PREDICTION**"
      ],
      "metadata": {
        "id": "LvJ2B1YbGHKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the Necessary Libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "PSfcuYHOA-4B"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv(\"diabetes_prediction_dataset.csv\")"
      ],
      "metadata": {
        "id": "E8nDatvRA-1j"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "X = data.drop(\"diabetes\", axis=1)\n",
        "y = data[\"diabetes\"]"
      ],
      "metadata": {
        "id": "0FH1VeKXA-yt"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "DK7tpptJA-vg"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define which features need one-hot encoding\n",
        "categorical_features = [\"gender\", \"smoking_history\"]\n"
      ],
      "metadata": {
        "id": "e-6iNI9JA-qB"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a column transformer for preprocessing\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), X_train.columns.difference(categorical_features)),\n",
        "        (\"cat\", OneHotEncoder(), categorical_features)\n",
        "    ])"
      ],
      "metadata": {
        "id": "NsQs09iQA-ml"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit and transform the data\n",
        "X_train_scaled = preprocessor.fit_transform(X_train)\n",
        "X_test_scaled = preprocessor.transform(X_test)"
      ],
      "metadata": {
        "id": "xPRyZ5nxA-dn"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize models\n",
        "models = [\n",
        "    (\"Logistic Regression\", LogisticRegression(max_iter=1000)),\n",
        "    (\"Decision Tree\", DecisionTreeClassifier()),\n",
        "    (\"Random Forest\", RandomForestClassifier()),\n",
        "    (\"Support Vector Machine\", SVC()),\n",
        "    (\"K-Nearest Neighbors\", KNeighborsClassifier())\n",
        "]"
      ],
      "metadata": {
        "id": "oK1td8KaECQo"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store results\n",
        "results = {}"
      ],
      "metadata": {
        "id": "dYlmSAI3Eoh3"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate each model\n",
        "for name, model in models:\n",
        "    print(f\"Training {name}...\")\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"{name} Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"Classification Report for {name}:\\n{classification_report(y_test, y_pred)}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQjaEzKTECNx",
        "outputId": "66feb13c-07ee-48ea-a3af-1ddcdeea1965"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Logistic Regression...\n",
            "Logistic Regression Accuracy: 0.96\n",
            "Classification Report for Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98     18292\n",
            "           1       0.86      0.62      0.72      1708\n",
            "\n",
            "    accuracy                           0.96     20000\n",
            "   macro avg       0.91      0.80      0.85     20000\n",
            "weighted avg       0.96      0.96      0.96     20000\n",
            "\n",
            "==================================================\n",
            "Training Decision Tree...\n",
            "Decision Tree Accuracy: 0.95\n",
            "Classification Report for Decision Tree:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97     18292\n",
            "           1       0.72      0.73      0.72      1708\n",
            "\n",
            "    accuracy                           0.95     20000\n",
            "   macro avg       0.85      0.85      0.85     20000\n",
            "weighted avg       0.95      0.95      0.95     20000\n",
            "\n",
            "==================================================\n",
            "Training Random Forest...\n",
            "Random Forest Accuracy: 0.97\n",
            "Classification Report for Random Forest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98     18292\n",
            "           1       0.94      0.69      0.79      1708\n",
            "\n",
            "    accuracy                           0.97     20000\n",
            "   macro avg       0.96      0.84      0.89     20000\n",
            "weighted avg       0.97      0.97      0.97     20000\n",
            "\n",
            "==================================================\n",
            "Training Support Vector Machine...\n",
            "Support Vector Machine Accuracy: 0.96\n",
            "Classification Report for Support Vector Machine:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98     18292\n",
            "           1       0.98      0.57      0.72      1708\n",
            "\n",
            "    accuracy                           0.96     20000\n",
            "   macro avg       0.97      0.79      0.85     20000\n",
            "weighted avg       0.96      0.96      0.96     20000\n",
            "\n",
            "==================================================\n",
            "Training K-Nearest Neighbors...\n",
            "K-Nearest Neighbors Accuracy: 0.96\n",
            "Classification Report for K-Nearest Neighbors:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98     18292\n",
            "           1       0.89      0.61      0.72      1708\n",
            "\n",
            "    accuracy                           0.96     20000\n",
            "   macro avg       0.93      0.80      0.85     20000\n",
            "weighted avg       0.96      0.96      0.96     20000\n",
            "\n",
            "==================================================\n",
            "Done!\n"
          ]
        }
      ]
    }
  ]
}